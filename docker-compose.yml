services:
  webapp:
    build: .
    ports:
      - "8000:8000"
    environment:
      VECTOR_DB: "qdrant"
      LLM_PROVIDER: "openai"
    volumes:
      - ./data:/app/data
    depends_on:
      - qdrant
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:v1.16
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped

  vllm:
    image: vllm/vllm-openai:latest
    environment:
      - VLLM_CPU_ONLY=1
    command: >
      --model TinyLlama/TinyLlama-1.1B-Chat-v1.0
      --port 8001
    ports:
      - "8001:8001"
    restart: unless-stopped

volumes:
  qdrant_data:
